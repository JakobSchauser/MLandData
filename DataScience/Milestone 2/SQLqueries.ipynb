{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "asdasdsa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('domain', 993400)\n",
      "20.9061\n",
      "('', 'id', 'domain', 'type', 'url', 'content', 'scraped_at', 'inserted_at', 'updated_at', 'title', 'authors', 'keywords', 'meta_keywords', 'meta_description', 'tags', 'summary', 'source')\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# con = sqlite3.connect('database.db')\n",
    "con = sqlite3.connect('1mio.db')\n",
    "\n",
    "# print(con)\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "quer1 = \"SELECT domain, count(type) FROM data WHERE type != 'reliable' ORDER BY count(type) DESC\"\n",
    "\n",
    "quer2 = \"SELECT count(type) FROM data WHERE instr(content, 'Trump') > 0\"\n",
    "\n",
    "quer3 = \"SELECT authors, count(type) FROM data GROUP BY authors ORDER BY count(type) DESC\"\n",
    "\n",
    "quer3 = \"SELECT * FROM data\"\n",
    "\n",
    "for row in cur.execute(quer1):\n",
    "    print(row)\n",
    "    break\n",
    "\n",
    "for row in cur.execute(quer2):\n",
    "    print(row[0]/1000000*100)\n",
    "\n",
    "for row in cur.execute(quer3):\n",
    "    print(row)\n",
    "    break\n",
    "# data = pd.read_csv(\"C:/Users/jakob/Downloads/FakeNews/news_sample.csv\")\n",
    "# data.head()\n",
    "# data.to_sql(\"data\", con, if_exists='append', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.9061"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "209061/1000000*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "con = sqlite3.connect(\"1mio.db\")\n",
    "cur = con.cursor()\n",
    "\n",
    "a_file = open(\"1mio-raw.csv\",encoding=\"utf8\")\n",
    "rows = csv.reader(a_file)\n",
    "cur.execute(\"CREATE TABLE data (unknown ,id, domain, type, url, content, scraped_at, inserted_at, updated_at, title, authors, keywords, meta_keywords, meta_description, tags, summary, source)\")\n",
    "cur.executemany(\"INSERT INTO data VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\", rows)\n",
    "\n",
    "cur.execute(\"SELECT * FROM data\")\n",
    "con.commit()\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92f83c05426f4916f717e7ba5a412ec12a5b79535648172354d400e07f6c6f36"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
