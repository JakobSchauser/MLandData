{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"Running on\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.genfromtxt(\"mnist_train.csv\", delimiter = \",\", skip_header = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dat[:,1:]/255.0, dat[:,0]\n",
    "\n",
    "X = torch.tensor(X, requires_grad=True, dtype = torch.double).view(-1,28,28).unsqueeze(1)\n",
    "\n",
    "y = torch.tensor(y, requires_grad=False, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 4\n",
    "plt.imshow(X[i].detach().numpy()[0])\n",
    "plt.title(str(y[i].numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def onehot(y):\n",
    "#     out = torch.zeros(y.shape[0],10)\n",
    "#     for i in range(y.shape[0]):\n",
    "#         out[i][y[i]] = 1\n",
    "#     return out\n",
    "\n",
    "def batch_loader(X,y, batch_size = 6):\n",
    "    for i in range(y.shape[0]//batch_size):\n",
    "        X_out = X[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "        y_out = y[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "        # y_out = onehot(y_out)\n",
    "        \n",
    "        yield X_out, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[[1, 3],\n",
    "         [0, 2]],\n",
    "\n",
    "        [[5, 7],\n",
    "         [4, 6]]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tra = pretrain(XXX[0], _type = 0)\n",
    "plt.imshow(tra[0][0][0])\n",
    "print(tra[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,SIZE = 100, pretrain = -1):\n",
    "        super (CNN, self).__init__()\n",
    "\n",
    "        features = 10\n",
    "        if pretrain == 0:\n",
    "            features = 4\n",
    "        if pretrain == 1:\n",
    "            features = 2\n",
    "        if pretrain == 2:\n",
    "            features = 2\n",
    "        if pretrain == 3:\n",
    "            features = 2\n",
    "\n",
    "        self.SIZE = SIZE\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(2, 2))\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=SIZE, kernel_size=(5, 5))\n",
    "        self.activation2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        self.linear1 = nn.Linear(in_features=SIZE*4*4, out_features=SIZE*4*4//2)\n",
    "        self.activation3 = nn.ReLU()\n",
    "\n",
    "        self.linear2 = nn.Linear(in_features=SIZE*4*4//2, out_features = features)\n",
    "        # self.final_activation = nn.Softmax(dim=0)\n",
    "        self.final_activation = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation1(self.conv1(x))\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.activation2(self.conv2(x))\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(-1,self.SIZE*4*4)\n",
    "        x = self.activation3(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        out = self.final_activation(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def pretrain(x, _type = 0):\n",
    "        l = x.shape[0]\n",
    "        _x = x.clone().detach()\n",
    "\n",
    "        if _type == 0:\n",
    "            n = np.random.randint(0,4, l)\n",
    "\n",
    "            for i in range(l):\n",
    "                _x[i] = torch.rot90(_x[i], int(n[i]), [1,2])\n",
    "                \n",
    "            y = n\n",
    "            \n",
    "        if _type == 1:\n",
    "            c = np.random.random(l)<0.5\n",
    "\n",
    "            # Wow!\n",
    "            b = torch.tensor(c.astype(int)).unsqueeze(1).unsqueeze(2).unsqueeze(3).expand(16,-1,28,28)\n",
    "\n",
    "            noise = torch.randn_like(_x)*0.1 * b \n",
    "            _x = _x + noise\n",
    "            \n",
    "            y = c\n",
    "            \n",
    "        if _type == 2:\n",
    "            c = np.random.random(l)<0.5\n",
    "\n",
    "            noise = torch.roll(_x, 1, 0) * torch.tensor(c.astype(int)).unsqueeze(1).unsqueeze(2).unsqueeze(3).expand(16,-1,28,28)\n",
    "            _x = _x + noise\n",
    "            y = c      \n",
    "        \n",
    "        return _x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(100)\n",
    "\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = 0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "def pretrain(model):\n",
    "    for i in range(n_epochs):\n",
    "        Loader = batch_loader(X,y, batch_size)\n",
    "        pbar = tqdm(Loader, total = y.shape[0]//batch_size)\n",
    "        for dat, _ in pbar:\n",
    "            dat, label = model.pretrain(dat, 0)\n",
    "            \n",
    "\n",
    "def train(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        Loader = batch_loader(X,y, batch_size)\n",
    "\n",
    "        c = 0\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "\n",
    "        pbar = tqdm(Loader, total = y.shape[0]//batch_size)\n",
    "        for dat, label in pbar:\n",
    "            pred = model(dat.float())\n",
    "\n",
    "            loss = loss_fn(pred, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss\n",
    "            epoch_acc += (label == pred.argmax(axis = 1)).float().mean()\n",
    "            c += 1\n",
    "\n",
    "            if c%10 == 0:\n",
    "                pbar.set_description(f\"loss {epoch_loss/c:.3} - acc {epoch_acc/c:.3}\")\n",
    "            # if c%100 == 0:\n",
    "                # print(pred[:5],label[:5],pred[:5].argmax(axis = 1) == label[:5])\n",
    "        print(f\"Epoch {i}/{n_epochs} - loss {epoch_loss/c:.3} - acc {epoch_acc/c:.3}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d9f9abb04043038e6d4d8dcee8194f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-84557d09d340>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-171-c8d69f4ce31a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(n_epochs)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakob\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakob\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90ddd5eea33bf34e5045df3efad123ec5baf581e702e7e2d1915bea2be814a0a"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
