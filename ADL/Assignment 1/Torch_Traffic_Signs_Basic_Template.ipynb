{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diBOWISLz3fV"
      },
      "source": [
        "# Basic CNN for traffic sign recognition\n",
        "## ADL 2022\n",
        "\n",
        "This notebook provides a template for a small CNN for the German Traffic Sign Recognition Benchmark. The data is described in:\n",
        "\n",
        "Johannes Stallkamp, Marc Schlipsing, Jan Salmen, and Christian Igel. Man vs. Computer: Benchmarking Machine Learning Algorithms for Traffic Sign Recognition. *Neural Networks* **32**, pp. 323-332, 2012\n",
        "\n",
        "This notebook is a template, without modification the model does not even come close to the state-of-the-art. \n",
        "\n",
        "Please [contact Stefan](mailto:sommer@di.ku.dk) if you have suggestions for improving the notebook.\n",
        "\n",
        "The original version of the notebook was written by [Christian Igel](mailto:igel@di.ku.dk). It has been slightly modified by [Stefan Sommer](mailto:sommer@di.ku.dk) and the TAs of ADL 2022."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hh3zJV20NKO"
      },
      "source": [
        "Do the imports first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_DEmCw_O1N4m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch \n",
        "import torch.optim as optim\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision.datasets.utils import download_url, extract_archive\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCmU86Yn0VW0"
      },
      "source": [
        "Check if a GPU is available:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ypjWR1XCKZzo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cpu\n"
          ]
        }
      ],
      "source": [
        "gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if gpu else \"cpu\")\n",
        "print(\"device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Krrag66A0Y7n"
      },
      "source": [
        "The GTSRB data wrapped in a `Dataset`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uKBCYtfv1YNC"
      },
      "outputs": [],
      "source": [
        "class GTSRBTrafficSigns(Dataset):\n",
        "  def __init__(self, root = './', url = 'https://sid.erda.dk/share_redirect/EB0rrpZwuI', filename='EB0rrpZwuI.zip', train=True, force_download=False): \n",
        "    self.img_height  = 32  \n",
        "    self.img_width   = self.img_height\n",
        "    self.img_height_crop = 28  \n",
        "    self.img_width_crop  = self.img_height_crop\n",
        "\n",
        "    self.train = train\n",
        "    archive = os.path.join(root, filename)\n",
        "\n",
        "    if self.train:\n",
        "      self.data_folder = os.path.join(root, 'GTSRB/train')\n",
        "    else:\n",
        "      self.data_folder = os.path.join(root, 'GTSRB/test')\n",
        "\n",
        "    if (not os.path.exists(self.data_folder)) or force_download:\n",
        "       download_url(url, root, filename)\n",
        "       extract_archive(archive, root, False)\n",
        "    else:\n",
        "      print('Using existing', self.data_folder)\n",
        "\n",
        "    self.dataset_train = datasets.ImageFolder(self.data_folder)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      image, label = self.dataset_train.__getitem__(index)\n",
        "      image = transforms.Resize((self.img_width,self.img_height))(image)\n",
        "      \n",
        "      if self.train:\n",
        "        image = transforms.RandomAffine((-5,5))(image)\n",
        "        image = transforms.RandomCrop((self.img_width_crop, self.img_height_crop))(image)\n",
        "        image = transforms.ColorJitter(0.8, contrast = 0.4)(image)\n",
        "        if label in [11, 12, 13, 17, 18, 26, 30, 35]:\n",
        "          image = transforms.RandomHorizontalFlip(p=0.5)(image)\n",
        "      else:\n",
        "        image = transforms.CenterCrop((self.img_width_crop, self.img_height_crop))(image)\n",
        "\n",
        "      image = transforms.ToTensor()(image)\n",
        "\n",
        "      return image, label\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.dataset_train.__len__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kxLuzusI3wgY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://sid.erda.dk/share_redirect/EB0rrpZwuI to ./EB0rrpZwuI.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "290897920it [00:29, 9818462.61it/s]                                \n"
          ]
        }
      ],
      "source": [
        "dataset_train = GTSRBTrafficSigns()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEoOq0fR0shZ"
      },
      "source": [
        "Define the data loader for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMvy6psj4Da3"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "generator_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4EPJdLb0yrN"
      },
      "source": [
        "Let's visualize some input images. This visualization is very important, among others to verify that the data augmentation works as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3bfL8fr4oby"
      },
      "outputs": [],
      "source": [
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(generator_train)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYoceXxa1LgG"
      },
      "source": [
        "Let's look at some images in the batch with their label:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rr9Zq9-O_TmF"
      },
      "outputs": [],
      "source": [
        "for i in range(0,batch_size,10):\n",
        "  imshow(images[i])\n",
        "  print(labels[i].item(), \"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCAWy9O-19t8"
      },
      "source": [
        "Define the neural network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTehyjtbAbUl"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, img_size=28):\n",
        "        super(Net, self).__init__()\n",
        "        # Add code here .... (see e.g. 'Switch to CNN' at https://pytorch.org/tutorials/beginner/nn_tutorial.html)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # And here ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdQ3MDpY2QOJ"
      },
      "source": [
        "Instantiate the neural network and potentially move it to GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k20BZnTt2N1a"
      },
      "outputs": [],
      "source": [
        "net = Net()\n",
        "if(gpu):\n",
        "  net.to(device)\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYFQ3dJf2a7q"
      },
      "source": [
        "Define loss and optimization algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4zMyMCTAQb4"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "## switch optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001, eps=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln380IT62sj-"
      },
      "source": [
        "These lines can be used to continue training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un0R8p_N2gPX"
      },
      "outputs": [],
      "source": [
        "cont = False\n",
        "if cont:\n",
        "  net.load_state_dict(torch.load('traffic_simple'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMaDlTva28hU"
      },
      "source": [
        "Do the training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzaIsMCVJQK6"
      },
      "outputs": [],
      "source": [
        "no_epochs = 200\n",
        "for epoch in range(no_epochs):  # Loop over the dataset multiple times\n",
        "    epoch_loss = running_loss = 0.0\n",
        "    for i, data in enumerate(generator_train, 0):\n",
        "        # Get the inputs; data is a list of [inputs, labels]\n",
        "        if (gpu):\n",
        "          inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        else:\n",
        "          inputs, labels = data\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics\n",
        "        reporting_interval = 100\n",
        "        epoch_loss += loss.item()\n",
        "        running_loss += loss.item()\n",
        "        if i % reporting_interval == reporting_interval-1:  # Print every reporting_interval mini-batches\n",
        "            # report_loss = running_loss / reproint\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / reporting_interval))\n",
        "            running_loss = 0.0\n",
        "    \n",
        "    # Log to tensorboard\n",
        "    writer.add_scalar(\"Loss/train\", epoch_loss/(i+1.), epoch)\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "writer.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN5_Zt8V3GFj"
      },
      "source": [
        "Evaluate on test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZueXQjDVJhAj"
      },
      "outputs": [],
      "source": [
        "dataset_test = GTSRBTrafficSigns(train=False)\n",
        "generator_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in generator_test:\n",
        "        if (gpu):\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "        else:\n",
        "          images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on test images: %.2f %%' % (100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWyvZX0y3IzO"
      },
      "source": [
        "Save network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ_hik0qMdEx"
      },
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'traffic_simple')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4JPHFU-HUCN"
      },
      "source": [
        "Visualize training with tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJ1GSYY7GRTX"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzbr1Y1lJjXU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Torch_Traffic_Signs_Basic_Template.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
