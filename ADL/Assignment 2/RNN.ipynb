{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch import tensor\n",
    "from torch.autograd import Variable\n",
    "from generate_data import generate_data, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "lr = 0.00005\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4*int(1e4)\n",
    "\n",
    "X, y = generate_data(N, is_short=True, type = 2)\n",
    "\n",
    "X_test, y_test = generate_data(2000, is_short=False, type = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_predictor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNN_predictor, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, nonlinearity='relu')\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "        self.activation = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        # hidden = Variable(torch.zeros(self.layer_dim, x.shape[1], self.hidden_dim))\n",
    "\n",
    "        # One time step\n",
    "        out, hn = self.rnn(x)\n",
    "        out = self.fc(out[ -1,:, :])\n",
    "        \n",
    "        return self.activation(out)\n",
    "\n",
    "\n",
    "model = RNN_predictor(3, 10, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN_predictor(\n",
      "  (rnn): RNN(3, 10)\n",
      "  (fc): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (activation): Softmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakob\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.69 - acc 0.532\n",
      "loss 0.655 - acc 0.781\n",
      "loss 0.525 - acc 0.793\n",
      "loss 0.405 - acc 0.816\n",
      "loss 0.337 - acc 0.836\n",
      "loss 0.383 - acc 0.782\n",
      "loss 0.382 - acc 0.796\n",
      "loss 0.328 - acc 0.83\n",
      "loss 0.282 - acc 0.908\n",
      "loss 0.28 - acc 0.819\n",
      "loss 0.436 - acc 0.775\n",
      "loss 0.548 - acc 0.539\n",
      "loss 0.622 - acc 0.504\n",
      "loss 0.644 - acc 0.542\n",
      "loss 0.648 - acc 0.502\n",
      "loss 0.648 - acc 0.501\n",
      "loss 0.643 - acc 0.56\n",
      "loss 0.636 - acc 0.526\n",
      "loss 0.628 - acc 0.555\n",
      "loss 0.619 - acc 0.563\n",
      "loss 0.595 - acc 0.663\n",
      "loss 0.498 - acc 0.769\n",
      "loss 0.399 - acc 0.792\n",
      "loss 0.399 - acc 0.8\n",
      "loss 0.384 - acc 0.796\n",
      "loss 0.396 - acc 0.786\n",
      "loss 0.398 - acc 0.792\n",
      "loss 0.397 - acc 0.789\n",
      "loss 0.395 - acc 0.782\n",
      "loss 0.392 - acc 0.785\n",
      "loss 0.385 - acc 0.784\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-0447cd47e434>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-73-0447cd47e434>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, n_epochs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0msum_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mi_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_batches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakob\\Documents\\MLandData\\ADL\\Assignment 2\\generate_data.py\u001b[0m in \u001b[0;36mdata_loader\u001b[1;34m(data, labels, batch_size, min_length)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0m_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0menc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0monehot_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakob\\Documents\\MLandData\\ADL\\Assignment 2\\generate_data.py\u001b[0m in \u001b[0;36monehot_encode\u001b[1;34m(data, min_length)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0monehot_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mencode_language\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0monehot_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakob\\Documents\\MLandData\\ADL\\Assignment 2\\generate_data.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0monehot_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mencode_language\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0monehot_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakob\\Documents\\MLandData\\ADL\\Assignment 2\\generate_data.py\u001b[0m in \u001b[0;36mencode_language\u001b[1;34m(l, min_length)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mencode_language\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mli\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mletter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    test_batches = data_loader(X_test,y_test,batch_size=32, min_length = 50)\n",
    "    acc = 0.0\n",
    "    i = 0\n",
    "    for data, labels in test_batches:\n",
    "        pred = model(data).view((-1,2))\n",
    "        corr = (torch.argmax(pred,1) == torch.argmax(labels,1)).float().mean().item()\n",
    "        acc += corr\n",
    "        i += 1\n",
    "    return acc/i\n",
    "\n",
    "def train(model,n_epochs):\n",
    "    parameters = model.parameters()\n",
    "\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        model.train()\n",
    "        train_batches = data_loader(X,y,batch_size=32, min_length = 20)\n",
    "\n",
    "        sum_loss = 0.0\n",
    "        i_loss = 0\n",
    "        for data, labels in train_batches:\n",
    "            pred = model(data)\n",
    "            loss_fn = F.binary_cross_entropy\n",
    "            loss = loss_fn(pred,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            sum_loss += loss.item()\n",
    "            i_loss += 1\n",
    "        print(f\"loss {sum_loss/i_loss:.3} - acc {test(model):.3}\")\n",
    "\n",
    "\n",
    "train(model,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90ddd5eea33bf34e5045df3efad123ec5baf581e702e7e2d1915bea2be814a0a"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
