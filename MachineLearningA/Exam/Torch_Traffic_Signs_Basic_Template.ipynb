{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diBOWISLz3fV"
   },
   "source": [
    "# Basic CNN for traffic sign recognition\n",
    "## Christian Igel, 2021\n",
    "\n",
    "This notebook provides a template for a small CNN for the German Traffic Sign Recognition Benchmark. The data is described in:\n",
    "\n",
    "Johannes Stallkamp, Marc Schlipsing, Jan Salmen, and Christian Igel. Man vs. Computer: Benchmarking Machine Learning Algorithms for Traffic Sign Recognition. *Neural Networks* **32**, pp. 323-332, 2012\n",
    "\n",
    "This notebook is a template, without modification the model does not even come close to the state-of-the-art. \n",
    "\n",
    "Please [contact me](mailto:igel@diku.dk) if you have suggestions for improving the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hh3zJV20NKO"
   },
   "source": [
    "Do the imports first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DEmCw_O1N4m"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.datasets.utils import download_url, extract_archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCmU86Yn0VW0"
   },
   "source": [
    "Check if a GPU is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypjWR1XCKZzo"
   },
   "outputs": [],
   "source": [
    "gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if gpu else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Krrag66A0Y7n"
   },
   "source": [
    "The GTSRB data wrapped in a `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKBCYtfv1YNC"
   },
   "outputs": [],
   "source": [
    "class GTSRBTrafficSigns(Dataset):\n",
    "  def __init__(self, root = './', url = 'https://sid.erda.dk/share_redirect/EB0rrpZwuI', filename='EB0rrpZwuI.zip', train=True, force_download=False): \n",
    "    self.img_height  = 32  \n",
    "    self.img_width   = self.img_height\n",
    "    self.img_height_crop = 28  \n",
    "    self.img_width_crop  = self.img_height_crop\n",
    "\n",
    "    self.train = train\n",
    "    archive = os.path.join(root, filename)\n",
    "\n",
    "    if self.train:\n",
    "      self.data_folder = os.path.join(root, 'GTSRB/train')\n",
    "    else:\n",
    "      self.data_folder = os.path.join(root, 'GTSRB/test')\n",
    "\n",
    "    if (not os.path.exists(self.data_folder)) or force_download:\n",
    "       download_url(url, root, filename)\n",
    "       extract_archive(archive, root, False)\n",
    "    else:\n",
    "      print('Using existing', self.data_folder)\n",
    "\n",
    "    self.dataset_train = datasets.ImageFolder(self.data_folder)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      image, label = self.dataset_train.__getitem__(index)\n",
    "      image = transforms.Resize((self.img_width,self.img_height))(image)\n",
    "      \n",
    "      if self.train:\n",
    "        image = transforms.RandomAffine((-5,5))(image)\n",
    "        image = transforms.RandomCrop((self.img_width_crop, self.img_height_crop))(image)\n",
    "        #image = transforms.ColorJitter(0.8, contrast = 0.4)(image)\n",
    "        if label in [11, 12, 13, 17, 18, 26, 30, 35]:\n",
    "          image = transforms.RandomHorizontalFlip(p=0.5)(image)\n",
    "      else:\n",
    "        image = transforms.CenterCrop((self.img_width_crop, self.img_height_crop))(image)\n",
    "        \n",
    "      image = transforms.ToTensor()(image)\n",
    "\n",
    "      return image, label\n",
    "\n",
    "  def __len__(self):\n",
    "      return self.dataset_train.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxLuzusI3wgY"
   },
   "outputs": [],
   "source": [
    "dataset_train = GTSRBTrafficSigns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEoOq0fR0shZ"
   },
   "source": [
    "Define the data loader for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMvy6psj4Da3"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "generator_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4EPJdLb0yrN"
   },
   "source": [
    "Let's visualize some input images. This visualization is very important, among others to verify that the data augmentation works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3bfL8fr4oby"
   },
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(generator_train)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYoceXxa1LgG"
   },
   "source": [
    "Let's look at each image in the batch with its label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rr9Zq9-O_TmF"
   },
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "  imshow(images[i])\n",
    "  print(labels[i].item(), \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCAWy9O-19t8"
   },
   "source": [
    "Define the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTehyjtbAbUl"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, img_size=28):\n",
    "        super(Net, self).__init__()\n",
    "        # Add code here ....\n",
    "\n",
    "    def forward(self, x):\n",
    "        # And here ...\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdQ3MDpY2QOJ"
   },
   "source": [
    "Instantiate the neural network and potentially move it to GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k20BZnTt2N1a"
   },
   "outputs": [],
   "source": [
    "net = Net()\n",
    "if(gpu):\n",
    "  net.to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYFQ3dJf2a7q"
   },
   "source": [
    "Define loss and optimization algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4zMyMCTAQb4"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, eps=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ln380IT62sj-"
   },
   "source": [
    "These lines can be used to continue training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Un0R8p_N2gPX"
   },
   "outputs": [],
   "source": [
    "cont = False\n",
    "if cont:\n",
    "  net.load_state_dict(torch.load('traffic_simple'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMaDlTva28hU"
   },
   "source": [
    "Do the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzaIsMCVJQK6"
   },
   "outputs": [],
   "source": [
    "no_epochs = 200\n",
    "for epoch in range(no_epochs):  # Loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(generator_train, 0):\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        if (gpu):\n",
    "          inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        else:\n",
    "          inputs, labels = data\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        reporting_interval = 100\n",
    "        running_loss += loss.item()\n",
    "        if i % reporting_interval == reporting_interval-1:  # Print every reporting_interval mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / reporting_interval))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aN5_Zt8V3GFj"
   },
   "source": [
    "Evaluate on test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZueXQjDVJhAj"
   },
   "outputs": [],
   "source": [
    "dataset_test = GTSRBTrafficSigns(train=False)\n",
    "generator_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in generator_test:\n",
    "        if (gpu):\n",
    "          images, labels = data[0].to(device), data[1].to(device)\n",
    "        else:\n",
    "          images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on test images: %.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWyvZX0y3IzO"
   },
   "source": [
    "Save network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQ_hik0qMdEx"
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'traffic_simple')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Torch Traffic Signs Basic Template.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
