{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing variable importance using logistic regression\n",
    "### Christian Igel, 2021\n",
    "\n",
    "This notebook demonstrates how to analyze variable importance using logistic regression. It reimplements the example in R from https://stats.idre.ucla.edu/r/dae/logit-regression/ in Python. It is reassuring to reproduce the R results. \n",
    "\n",
    "It is important that we do not use the logistic regression from scikit-learn but from [statmodels](https://www.statsmodels.org/). First, we will do the data preprocessing using [pandas](https://pandas.pydata.org/) to organize the data, then we will make use of [patsy](https://patsy.readthedocs.io).\n",
    "\n",
    "Any suggestions for improvements are more than welcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to predict admission into graduate school based on  GRE (Graduate Record Exam scores), GPA (grade point average) and prestige of the undergraduate institution. Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/binary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First version\n",
    "In the first version, we do the main data preprocessing steps ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict/explain the binary variable `admit` given the other variables. Thus, we split data into input (predictor variables) and target (response/dependent variable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:4]\n",
    "y = df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We treat the `rank`, which indicates the prestige of the undergraduate institution, as a categorical variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"rank\"] = X[\"rank\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we transform the categorical variable. Note that in contrast to a one-hot-encoding one column is dropped to avoid the linear dependency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_transformed = pd.get_dummies(X, prefix=['rank'], drop_first=True)\n",
    "X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model we are using does not have a built in intercept (bias/offset) parameter. Thus, we augment our input data with a constant dummy variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_transformed = sm.add_constant(X_transformed)\n",
    "X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute and inspect the logistic regression model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model=sm.Logit(y, X_transformed)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second version, we use a library function for creating design matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a formula syntax to specify the design matrix as in R. When a formula is used to specify the terms to include in the design martrix, a constant for the intercept term will be included by default. The function `C` handles the encoding of the categorical varibale for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices('admit ~ gre + gpa + C(rank)', df, return_type = 'dataframe')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = sm.Logit(y, X)\n",
    "result = logit.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting the resuls\n",
    "\n",
    "The results table  shows the coefficients, their standard errors, the z-statistic (sometimes called a Wald z-statistic, in this case the z-value is computed as the coefficient over its standard error, a concept we have not discussed in the lecture), the associated p-values (P), as well as the confidence intervals for the coefficient estimates. \n",
    "\n",
    "Assuming a 5% significance level, one can argue that all predictor variables are statistically significant, because their p-values are all smaller than 0.05. (The null hypothesis is that the coefficient is zero. If the p-value is smaller than our significnace level, we reject the null hypothesis.) \n",
    "\n",
    "\"The logistic regression coefficients give the change in the log odds of the outcome for a one unit increase in the predictor variable. For every one unit change in `gre`, the log odds of admission (versus non-admission) increases by 0.002. For a one unit increase in `gpa`, the log odds of being admitted to graduate school increases by 0.804. The indicator variables for `rank` have a slightly different interpretation. For example, having attended an undergraduate institution with `rank` of 2, versus an institution with a `rank` of 1, changes the log odds of admission by -0.675\" [(quoted from here)](https://stats.idre.ucla.edu/r/dae/logit-regression/).\n",
    "\n",
    "The accuracy of the model on the training set, which is *not* an ubiased estimate of the generalizaition performance, can be computed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = result.predict(X)  # Predict using the result object\n",
    "print('Accuracy on training set:', \n",
    "      accuracy_score(y, [1 if m >= 0.5 else 0 for m in y_pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional comments\n",
    "In the following, it is demonstrated that linear rescaling does not change the significance of the the predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "cols_to_norm = ['gre','gpa']\n",
    "X[cols_to_norm] = StandardScaler().fit_transform(X[cols_to_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = sm.Logit(y, X)\n",
    "result = logit.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the p-values of the predictor variables did not change, as it should be. \n",
    "(However, we can not reject the null hypothesis that the intercept parameter is zero, zero is also in the confidence interval of the intercept estimate.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
